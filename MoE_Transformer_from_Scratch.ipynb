{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets tokenizer torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is_RBGmzQxwd",
        "outputId": "558f5ebc-4dac-4013-8d13-8ba3e5e9409e"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.21.0)\n",
            "Requirement already satisfied: tokenizer in /usr/local/lib/python3.10/dist-packages (3.4.4)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.3.1+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (71.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics) (12.6.20)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "iVgmbCSsYh5u"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "import torchmetrics\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class InputEmbeddings(nn.Module):\n",
        "    def __init__(self, d_model: int, vocab_size: int) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (batch, seq_len)  -->  (batch, seq_len, d_model)\n",
        "        # Also scale the embeddings with sqrt(d_model)\n",
        "        return self.embedding(x) * math.sqrt(self.d_model)"
      ],
      "metadata": {
        "id": "SoA1YDicZeYQ"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, seq_len: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.seq_len = seq_len\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        positional_encodings = torch.zeros(seq_len, d_model)   # --> (seq_len, d_model)\n",
        "        positions = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)   # --> (seq_len, 1)\n",
        "        odd_even_positions = torch.arange(0, d_model, 2).float()  # --> 2i\n",
        "        div_term = torch.pow(10000, odd_even_positions/d_model)  # --> 10000**(2i/d_model)\n",
        "        positional_encodings[:, 0::2] = torch.sin(positions*div_term)  # --> (even positions terms)\n",
        "        positional_encodings[:, 1::2] = torch.cos(positions*div_term)  # --> (odd positions terms)\n",
        "\n",
        "        # add batch size\n",
        "        positional_encodings = positional_encodings.unsqueeze(0)   # --> (1, seq_len, d_model)\n",
        "        self.register_buffer('positional_encodings', positional_encodings)   # to be a part of module state but not as a paramter of module state\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + (self.positional_encodings[:, :x.shape[1], :]).requires_grad_(False)   # --> (batch, seq_len, d_model) + (1, seq_len, d_model) = (batch, seq_len, d_model)\n",
        "        return self.dropout(x)\n"
      ],
      "metadata": {
        "id": "p8JhI5IqbMCr"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, features: int, eps:float=10**-6) -> None:\n",
        "        super().__init__()\n",
        "        self.eps = eps   # very small number to avoid division by zero\n",
        "        self.alpha = nn.Parameter(torch.ones(features)) # alpha is a learnable parameter\n",
        "        self.bias = nn.Parameter(torch.zeros(features)) # bias is a learnable parameter\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x --> (batch, seq_len, d_model)\n",
        "        mean = x.mean(dim = -1, keepdim = True)  # --> (batch, seq_len, 1)\n",
        "        std = x.std(dim = -1, keepdim = True)  # --> (batch, seq_len, 1)\n",
        "        return self.alpha * (x - mean) / (std + self.eps) + self.bias\n"
      ],
      "metadata": {
        "id": "UEFE_RrlnwPC"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForwardBlock(nn.Module):\n",
        "    def __init__(self, d_model: int, d_ff: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear_1 = nn.Linear(in_features = d_model, out_features = d_ff)\n",
        "        self.linear_2 = nn.Linear(in_features = d_ff, out_features = d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (batch, seq_len, d_model) --> (batch, seq_len, d_ff) --> (batch, seq_len, d_model)\n",
        "        return self.linear_2(self.dropout(torch.relu(self.linear_1(x))))"
      ],
      "metadata": {
        "id": "fSdV7cdN39H4"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionBlock(nn.Module):\n",
        "    def __init__(self, d_model: int, h: int, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.h = h  # number of heads\n",
        "\n",
        "        # number of heads should be divisible by d_model\n",
        "        assert d_model % h == 0, \"d_model is not divisible by h\"\n",
        "\n",
        "        self.d_k = d_model // h   # Dimension of vector seen by each head\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.w_q = nn.Linear(in_features = d_model, out_features = d_model)\n",
        "        self.w_k = nn.Linear(in_features = d_model, out_features = d_model)\n",
        "        self.w_v = nn.Linear(in_features = d_model, out_features = d_model)\n",
        "        self.w_o = nn.Linear(in_features = d_model, out_features = d_model)\n",
        "\n",
        "    @staticmethod\n",
        "    def attention(query, key, value, mask, dropout : nn.Dropout):\n",
        "        d_k = query.shape[-1]\n",
        "\n",
        "        # (batch, h, seq_len, d_k) --> (batch, h, seq_len, seq_len)\n",
        "        attention_scores = (query @ key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "\n",
        "        if mask is not None:\n",
        "            # Where ever the mask == 0 change the value of attention score of that position as -INF\n",
        "            attention_scores.masked_fill_(mask == 0, -1e9)\n",
        "\n",
        "        attention_scores = attention_scores.softmax(dim=-1) # (batch, h, seq_len, seq_len)\n",
        "\n",
        "        if dropout is not None:\n",
        "            attention_scores = dropout(attention_scores)\n",
        "\n",
        "        # (batch, h, seq_len, seq_len) --> (batch, h, seq_len, d_k)\n",
        "        return (attention_scores @ value), attention_scores\n",
        "\n",
        "\n",
        "    def forward(self, q, k, v, mask):\n",
        "        query = self.w_q(q) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "        key = self.w_k(k) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "        value = self.w_v(v) # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "\n",
        "        # (batch, seq_len, d_model) --> (batch, seq_len, h, d_k) --> (batch, h, seq_len, d_k)\n",
        "        query = query.view(query.shape[0], query.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        key = key.view(key.shape[0], key.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "        value = value.view(value.shape[0], value.shape[1], self.h, self.d_k).transpose(1, 2)\n",
        "\n",
        "        # Calculate attention\n",
        "        x, self.attention_scores = MultiHeadAttentionBlock.attention(query, key, value, mask, self.dropout)\n",
        "\n",
        "        # Combine all the heads together\n",
        "        # (batch, h, seq_len, d_k) --> (batch, seq_len, h, d_k) --> (batch, seq_len, d_model)\n",
        "        x = x.transpose(1, 2).contiguous().view(x.shape[0], -1, self.h * self.d_k)\n",
        "\n",
        "        # (batch, seq_len, d_model) --> (batch, seq_len, d_model)\n",
        "        return self.w_o(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "xEvQUMJ16UIi"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualConnection(nn.Module):\n",
        "        def __init__(self, features: int, dropout: float) -> None:\n",
        "            super().__init__()\n",
        "            self.dropout = nn.Dropout(dropout)\n",
        "            self.norm = LayerNormalization(features)\n",
        "\n",
        "        def forward(self, x, sublayer):\n",
        "            return x + self.dropout(sublayer(self.norm(x)))"
      ],
      "metadata": {
        "id": "9FWMUjnDF76N"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NoisyTopkRouter(nn.Module):\n",
        "    def __init__(self, d_model: int, num_experts: int, top_k: int) -> None:\n",
        "        super(NoisyTopkRouter, self).__init__()\n",
        "        self.top_k = top_k\n",
        "        self.topkroute_linear = nn.Linear(in_features = d_model, out_features = num_experts)\n",
        "        self.noise_linear = nn.Linear(in_features = d_model, out_features = num_experts)\n",
        "\n",
        "    def forward(self, mh_output):\n",
        "        # (batch, seq_len, d_model) --> (batch, seq_len, num_experts)\n",
        "        logits = self.topkroute_linear(mh_output)\n",
        "        noise_logits = self.noise_linear(mh_output)\n",
        "\n",
        "        noise = torch.randn_like(logits)*F.softplus(noise_logits)\n",
        "        noisy_logits = logits + noise # (batch, seq_len, num_experts)\n",
        "\n",
        "        top_k_logits, indices = noisy_logits.topk(self.top_k, dim=-1)  # (batch, seq_len, top_k)\n",
        "        zeros = torch.full_like(noisy_logits, float('-inf'))  # (batch, seq_len, num_experts)\n",
        "        sparse_logits = zeros.scatter(-1, indices, top_k_logits)  # (batch, seq_len, num_experts)\n",
        "        router_output = F.softmax(sparse_logits, dim=-1)\n",
        "        return router_output, indices"
      ],
      "metadata": {
        "id": "Y7y5HadtIUl3"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SparseMoE(nn.Module):\n",
        "    def __init__(self, d_model: int, num_experts: int, top_k: int, d_ff: int, dropout: float) -> None:\n",
        "        super(SparseMoE, self).__init__()\n",
        "        self.router = NoisyTopkRouter(d_model, num_experts, top_k)\n",
        "        self.experts = nn.ModuleList([FeedForwardBlock(d_model, d_ff, dropout) for _ in range(num_experts)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x --> (batch, seq_len, d_model)\n",
        "        gating_output, indices = self.router(x)  # (batch, seq_len, num_experts)  ,  (batch, seq_len, top_k)\n",
        "        final_output = torch.zeros_like(x)       # (batch, seq_len, d_model)\n",
        "\n",
        "        flat_x = x.view(-1, x.size(-1))  # (batch * seq_len, d_model)\n",
        "        flat_gating_output = gating_output.view(-1, gating_output.size(-1))  # (batch * seq_len, num_experts)\n",
        "\n",
        "        for i, experts in enumerate(self.experts):\n",
        "            expert_mask = (indices == i).any(dim=-1)  #(batch, seq_len)  return bool value if ith expert is assigned.\n",
        "            flat_expert_mask = expert_mask.view(-1)  # (batch * seq_len)  boolean values indicating if the ith expert is considered for the paticular token\n",
        "\n",
        "            if flat_expert_mask.any():  # if the ith expert is assigned to any token\n",
        "                expert_input = flat_x[flat_expert_mask]   # considering all those tokens which have been considered for ith expert\n",
        "                expert_output = experts(expert_input)   # getting output for the tokens considered using the ith expert\n",
        "\n",
        "                # now the gating score calculate earlier provides the weight to assign to a paticular expert for a given token, if we have considered 2 experts out of 8 for a given token\n",
        "                # then gating_output will have 0 marked for experts which are not considered and a value for the 2 experts considered and those values provides the weight of that expert.\n",
        "                gating_scores = flat_gating_output[flat_expert_mask, i].unsqueeze(1)  # we need to consider the token which have been assigned to ith expert, since every token is assigned with 2 expert we need to consider the value of the ith expert from the gating_output (out of 2 expert taken we want the gating value of the ith expert for that token)\n",
        "                weighted_output = expert_output * gating_scores\n",
        "\n",
        "                final_output[expert_mask] += weighted_output.squeeze(1)\n",
        "\n",
        "        return final_output\n"
      ],
      "metadata": {
        "id": "qhtNoyJeOSdr"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, features: int, self_attention_block: MultiHeadAttentionBlock, moe: SparseMoE, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.self_attention_block = self_attention_block\n",
        "        self.moe = moe\n",
        "        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(2)])\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, src_mask))      # passing the original input and multi-head attention function\n",
        "        x = self.residual_connections[1](x, lambda x: self.moe(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "OQbsj64DWq9O"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, features: int, layers: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.norm = LayerNormalization(features)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "id": "4cRqBqwXYWHf"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, features: int, self_attention_block: MultiHeadAttentionBlock, cross_attention_block: MultiHeadAttentionBlock, moe: SparseMoE, dropout: float) -> None:\n",
        "        super().__init__()\n",
        "        self.self_attention_block = self_attention_block\n",
        "        self.cross_attention_block = cross_attention_block\n",
        "        self.moe = moe\n",
        "        self.residual_connections = nn.ModuleList([ResidualConnection(features, dropout) for _ in range(3)])\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "        x = self.residual_connections[0](x, lambda x: self.self_attention_block(x, x, x, tgt_mask))\n",
        "        x = self.residual_connections[1](x, lambda x: self.cross_attention_block(x, encoder_output, encoder_output, src_mask))\n",
        "        x = self.residual_connections[2](x, lambda x: self.moe(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "CsfAlaozaH5j"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, features: int, layers: nn.ModuleList) -> None:\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.norm = LayerNormalization(features)\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output, src_mask, tgt_mask)\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "id": "NBhtvRyxsE6i"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProjectionLayer(nn.Module):\n",
        "    def __init__(self, d_model: int, vocab_size: int) -> None:\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (batch, seq_len, d_model) --> (batch, seq_len, vocab_size)\n",
        "        return self.proj(x)"
      ],
      "metadata": {
        "id": "fudiof8asK4v"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder: Encoder, decoder: Decoder, src_embed: InputEmbeddings, tgt_embed: InputEmbeddings, src_pos: PositionalEncoding, tgt_pos: PositionalEncoding, projection_layer: ProjectionLayer) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.src_pos = src_pos\n",
        "        self.tgt_pos = tgt_pos\n",
        "        self.projection_layer = projection_layer\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        # (batch, seq_len) --> (batch, seq_len, d_model)\n",
        "        src = self.src_embed(src)\n",
        "        src = self.src_pos(src)\n",
        "        return self.encoder(src, src_mask)\n",
        "\n",
        "    def decode(self, encoder_output, src_mask, tgt, tgt_mask):\n",
        "        # (batch, seq_len) --> (batch, seq_len, d_model)\n",
        "        tgt = self.tgt_embed(tgt)\n",
        "        tgt = self.tgt_pos(tgt)\n",
        "        return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\n",
        "\n",
        "    def project(self, x):\n",
        "        # (batch, seq_len, d_model) --> (batch, seq_len, vocab_size)\n",
        "        return self.projection_layer(x)"
      ],
      "metadata": {
        "id": "z1TTtFR_jr0H"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_transformer(src_vocab_size: int, tgt_vocab_size: int, src_seq_len: int, tgt_seq_len: int, d_model: int=512, N: int=6, h: int=8, num_experts: int=8, top_k: int=2, dropout: float=0.1, d_ff: int=2048) -> Transformer:\n",
        "    # Create the embedding layers\n",
        "    src_embed = InputEmbeddings(d_model, src_vocab_size)\n",
        "    tgt_embed = InputEmbeddings(d_model, tgt_vocab_size)\n",
        "\n",
        "    # Create the positional encoding layers\n",
        "    src_pos = PositionalEncoding(d_model, src_seq_len, dropout)\n",
        "    tgt_pos = PositionalEncoding(d_model, tgt_seq_len, dropout)\n",
        "\n",
        "    # Create the encoder blocks\n",
        "    encoder_blocks = []\n",
        "    for _ in range(N):\n",
        "        encoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        encoder_moe = SparseMoE(d_model, num_experts, top_k, d_ff, dropout)\n",
        "        encoder_block = EncoderBlock(d_model, encoder_self_attention_block, encoder_moe, dropout)\n",
        "        encoder_blocks.append(encoder_block)\n",
        "\n",
        "    # Create the decoder blocks\n",
        "    decoder_blocks = []\n",
        "    for _ in range(N):\n",
        "        decoder_self_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        decoder_cross_attention_block = MultiHeadAttentionBlock(d_model, h, dropout)\n",
        "        decoder_moe = SparseMoE(d_model, num_experts, top_k, d_ff, dropout)\n",
        "        decoder_block = DecoderBlock(d_model, decoder_self_attention_block, decoder_cross_attention_block, decoder_moe, dropout)\n",
        "        decoder_blocks.append(decoder_block)\n",
        "\n",
        "    # Create the encoder and decoder\n",
        "    encoder = Encoder(d_model, nn.ModuleList(encoder_blocks))\n",
        "    decoder = Decoder(d_model, nn.ModuleList(decoder_blocks))\n",
        "\n",
        "    # Create the projection layer\n",
        "    projection_layer = ProjectionLayer(d_model, tgt_vocab_size)\n",
        "\n",
        "    # Create the transformer\n",
        "    transformer = Transformer(encoder, decoder, src_embed, tgt_embed, src_pos, tgt_pos, projection_layer)\n",
        "\n",
        "    # Initialize the parameters\n",
        "    for p in transformer.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "\n",
        "    return transformer"
      ],
      "metadata": {
        "id": "EjwLw7P-HaSt"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset - https://huggingface.co/datasets/Helsinki-NLP/opus_books\n",
        "\n",
        "# An iterator iterating the dataset which is a dictonary of source lang to target lang.\n",
        "def get_all_sentences(ds, lang):\n",
        "    for item in ds:\n",
        "        yield item['translation'][lang]\n",
        "\n",
        "\n",
        "# Creating tokenizer for dataset of a paticular language using hugging face tokenizer library. Source - https://huggingface.co/docs/tokenizers/quicktour\n",
        "def get_or_build_tokenizer(config, ds, lang):\n",
        "    tokenizer_path = Path(config['tokenizer_file'].format(lang))   # tokenizer path. str.format() function insert dynamically insert the value of lang into a string template stored in. Example if the file path is tokenizer_{0}.json then if we apply format function it will change it to tokenizer_{lang}.json.\n",
        "    if not Path.exists(tokenizer_path):   # If tokenizer file does not exist\n",
        "        tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
        "        tokenizer.pre_tokenizer = Whitespace()\n",
        "        trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[PAD]\", \"[SOS]\", \"[EOS]\"], min_frequency=2)\n",
        "        tokenizer.train_from_iterator(get_all_sentences(ds, lang), trainer=trainer)\n",
        "        tokenizer.save(str(tokenizer_path))\n",
        "    else:\n",
        "        tokenizer = Tokenizer.from_file(str(tokenizer_path))\n",
        "    return tokenizer\n"
      ],
      "metadata": {
        "id": "V3WojMa1T3kD"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BilingualDataset(Dataset):\n",
        "    def __init__(self, ds, tokenizer_src, tokenizer_tgt, src_lang, tgt_lang, seq_len):\n",
        "        super().__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.ds = ds\n",
        "        self.tokenizer_src = tokenizer_src\n",
        "        self.tokenizer_tgt = tokenizer_tgt\n",
        "        self.src_lang = src_lang\n",
        "        self.tgt_lang = tgt_lang\n",
        "\n",
        "        self.sos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[SOS]\")], dtype=torch.int64)\n",
        "        self.eos_token = torch.tensor([tokenizer_tgt.token_to_id(\"[EOS]\")], dtype=torch.int64)\n",
        "        self.pad_token = torch.tensor([tokenizer_tgt.token_to_id(\"[PAD]\")], dtype=torch.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_target_pair = self.ds[idx]\n",
        "        src_text = src_target_pair['translation'][self.src_lang]\n",
        "        tgt_text = src_target_pair['translation'][self.tgt_lang]\n",
        "\n",
        "        # Transform the text into tokens\n",
        "        enc_input_tokens = self.tokenizer_src.encode(src_text).ids\n",
        "        dec_input_tokens = self.tokenizer_tgt.encode(tgt_text).ids\n",
        "\n",
        "        # Add SOS, EOS and padding to each sentence\n",
        "        enc_num_padding_tokens = self.seq_len - len(enc_input_tokens) - 2  # subrating with 2 because we need to add SOS and EOS token as well\n",
        "        dec_num_padding_tokens = self.seq_len - len(dec_input_tokens) - 1  # subrating with 1 beacause we only need to add SOS token to the decoder input and in case of label/target we only need to add EOS token\n",
        "\n",
        "        # Make sure the number of padding tokens is not negative. If it is, the sentence is too long\n",
        "        if enc_num_padding_tokens < 0 or dec_num_padding_tokens < 0:\n",
        "            raise ValueError(\"Sentence is too long\")\n",
        "\n",
        "        # Converting tokens into tensors and adding SOS, EOS and padding tokens\n",
        "        encoder_input = torch.cat(\n",
        "            [\n",
        "                self.sos_token,\n",
        "                torch.tensor(enc_input_tokens, dtype=torch.int64),\n",
        "                self.eos_token,\n",
        "                torch.tensor([self.pad_token] * enc_num_padding_tokens, dtype=torch.int64),\n",
        "            ],\n",
        "            dim=0,\n",
        "        )\n",
        "\n",
        "        # Converting tokens into tensors and adding SOS and padding token\n",
        "        decoder_input = torch.cat(\n",
        "            [\n",
        "                self.sos_token,\n",
        "                torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
        "                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64),\n",
        "            ],\n",
        "            dim=0,\n",
        "        )\n",
        "\n",
        "        # Converting tokens into tensors and adding EOS and padding token\n",
        "        label = torch.cat(\n",
        "            [\n",
        "                torch.tensor(dec_input_tokens, dtype=torch.int64),\n",
        "                self.eos_token,\n",
        "                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64),\n",
        "            ],\n",
        "            dim=0,\n",
        "        )\n",
        "\n",
        "        # Double check the size of the tensors to make sure they are all seq_len long\n",
        "        assert encoder_input.size(0) == self.seq_len\n",
        "        assert decoder_input.size(0) == self.seq_len\n",
        "        assert label.size(0) == self.seq_len\n",
        "\n",
        "        return {\n",
        "            \"encoder_input\": encoder_input,  # (seq_len)\n",
        "            \"decoder_input\": decoder_input,  # (seq_len)\n",
        "            \"encoder_mask\": (encoder_input != self.pad_token).unsqueeze(0).unsqueeze(0).int(), # (1, 1, seq_len)\n",
        "            \"decoder_mask\": (decoder_input != self.pad_token).unsqueeze(0).int() & causal_mask(decoder_input.size(0)), # (1, seq_len) & (1, seq_len, seq_len),\n",
        "            \"label\": label,  # (seq_len)\n",
        "            \"src_text\": src_text,\n",
        "            \"tgt_text\": tgt_text,\n",
        "        }\n",
        "\n",
        "def causal_mask(size):\n",
        "    mask = torch.triu(torch.ones((1, size, size)), diagonal=1).type(torch.int)\n",
        "    return mask == 0"
      ],
      "metadata": {
        "id": "s8X5Vcwexfh2"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ds(config):\n",
        "    ds_raw = load_dataset(f\"{config['datasource']}\", f\"{config['lang_src']}-{config['lang_tgt']}\", split='train')\n",
        "\n",
        "    tokenizer_src = get_or_build_tokenizer(config, ds_raw, config['lang_src'])\n",
        "    tokenizer_tgt = get_or_build_tokenizer(config, ds_raw, config['lang_tgt'])\n",
        "\n",
        "    # only train split availiable so we have to split it to train and validation\n",
        "    train_ds_size = int(0.9 * len(ds_raw))  # 90% train\n",
        "    val_ds_size = len(ds_raw) - train_ds_size  # 10% validation\n",
        "\n",
        "    train_ds_raw, val_ds_raw = random_split(ds_raw, [train_ds_size, val_ds_size])\n",
        "\n",
        "    train_ds = BilingualDataset(train_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
        "    val_ds = BilingualDataset(val_ds_raw, tokenizer_src, tokenizer_tgt, config['lang_src'], config['lang_tgt'], config['seq_len'])\n",
        "\n",
        "    # Find the maximum length of each sentence in the source and target sentence\n",
        "    max_len_src = 0\n",
        "    max_len_tgt = 0\n",
        "\n",
        "    for item in ds_raw:\n",
        "        src_ids = tokenizer_src.encode(item['translation'][config['lang_src']]).ids\n",
        "        tgt_ids = tokenizer_tgt.encode(item['translation'][config['lang_tgt']]).ids\n",
        "        max_len_src = max(max_len_src, len(src_ids))\n",
        "        max_len_tgt = max(max_len_tgt, len(tgt_ids))\n",
        "\n",
        "    print(f'Max length of source sentence: {max_len_src}')\n",
        "    print(f'Max length of target sentence: {max_len_tgt}')\n",
        "\n",
        "\n",
        "    train_dataloader = DataLoader(train_ds, batch_size=config['batch_size'], shuffle=True)\n",
        "    val_dataloader = DataLoader(val_ds, batch_size=1, shuffle=True)\n",
        "\n",
        "    return train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt\n"
      ],
      "metadata": {
        "id": "PpaU7PbfWcC6"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(config, vocab_src_len, vocab_tgt_len):\n",
        "    model = build_transformer(vocab_src_len, vocab_tgt_len, config[\"seq_len\"], config['seq_len'], d_model=config['d_model'], N=config['num_layers'], num_experts=config['num_experts'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "BcfrGw1BMBqs"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "          \"batch_size\": 16,\n",
        "          \"num_epochs\": 5,\n",
        "          \"lr\": 10**-3,\n",
        "          \"seq_len\": 350,\n",
        "          \"d_model\": 512,\n",
        "          \"datasource\": 'Helsinki-NLP/opus_books',\n",
        "          \"lang_src\": \"en\",\n",
        "          \"lang_tgt\": \"it\",\n",
        "          \"num_layers\": 2,\n",
        "          \"num_experts\": 4,\n",
        "          \"top_k\": 2,\n",
        "          \"model_folder\": \"weights\",\n",
        "          \"model_basename\": \"tmodel_\",\n",
        "          \"tokenizer_file\": \"tokenizer_{0}.json\",\n",
        "          \"experiment_name\": \"runs/tmodel\"\n",
        "        }"
      ],
      "metadata": {
        "id": "l9uLAJoJY2Fh"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weights_file_path(config, epoch: str):\n",
        "    model_folder = f\"{config['datasource']}_{config['model_folder']}\"\n",
        "    model_filename = f\"{config['model_basename']}{epoch}.pt\"\n",
        "    return str(Path('.') / model_folder / model_filename)"
      ],
      "metadata": {
        "id": "yV7YPFzZbMUp"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the latest weights file in the weights folder\n",
        "def latest_weights_file_path(config):\n",
        "    model_folder = f\"{config['datasource']}_{config['model_folder']}\"\n",
        "    model_filename = f\"{config['model_basename']}*\"\n",
        "    weights_files = list(Path(model_folder).glob(model_filename))\n",
        "    if len(weights_files) == 0:\n",
        "        return None\n",
        "    weights_files.sort()\n",
        "    return str(weights_files[-1])"
      ],
      "metadata": {
        "id": "mgbvCd3OKqKV"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(config):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    # Make sure the weights folder exists\n",
        "    Path(f\"{config['datasource']}_{config['model_folder']}\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
        "    model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
        "    # Tensorboard\n",
        "    writer = SummaryWriter(config['experiment_name'])\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], eps=1e-9)\n",
        "\n",
        "    initial_epoch = 0\n",
        "    global_step = 0\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer_src.token_to_id('[PAD]'), label_smoothing=0.1).to(device)\n",
        "\n",
        "    for epoch in range(initial_epoch, config['num_epochs']):\n",
        "        model.train()\n",
        "        batch_iterator = tqdm(train_dataloader, desc=f\"Processing Epoch {epoch:02d}\")\n",
        "        for batch in batch_iterator:\n",
        "\n",
        "            encoder_input = batch['encoder_input'].to(device) # (B, seq_len)\n",
        "            decoder_input = batch['decoder_input'].to(device) # (B, seq_len)\n",
        "            encoder_mask = batch['encoder_mask'].to(device) # (B, 1, 1, seq_len)\n",
        "            decoder_mask = batch['decoder_mask'].to(device) # (B, 1, seq_len, seq_len)\n",
        "\n",
        "            # Run the tensors through the encoder, decoder and the projection layer\n",
        "            encoder_output = model.encode(encoder_input, encoder_mask) # (B, seq_len, d_model)\n",
        "            decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask) # (B, seq_len, d_model)\n",
        "            proj_output = model.project(decoder_output) # (B, seq_len, vocab_size)\n",
        "\n",
        "            # Compare the output with the label\n",
        "            label = batch['label'].to(device) # (B, seq_len)\n",
        "\n",
        "            # Compute the loss using a simple cross entropy\n",
        "            # (B, seq_len, vocab_size) --> (B * seq_len, vocab_size)\n",
        "            loss = loss_fn(proj_output.view(-1, tokenizer_tgt.get_vocab_size()), label.view(-1))\n",
        "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
        "\n",
        "            # Log the loss\n",
        "            writer.add_scalar('train loss', loss.item(), global_step)\n",
        "            writer.flush()\n",
        "\n",
        "            # Backpropagate the loss\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the weights\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "        # Save the model at the end of every epoch\n",
        "        model_filename = get_weights_file_path(config, f\"{epoch:02d}\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'global_step': global_step\n",
        "        }, model_filename)"
      ],
      "metadata": {
        "id": "9HCtgxPKf2ao"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode(model, source, source_mask, tokenizer_src, tokenizer_tgt, max_len, device):\n",
        "    sos_idx = tokenizer_tgt.token_to_id('[SOS]')\n",
        "    eos_idx = tokenizer_tgt.token_to_id('[EOS]')\n",
        "\n",
        "    # Precompute the encoder output and reuse it for every step\n",
        "    encoder_output = model.encode(source, source_mask)\n",
        "    # Initialize the decoder input with the sos token\n",
        "    decoder_input = torch.empty(1, 1).fill_(sos_idx).type_as(source).to(device)\n",
        "    while True:\n",
        "        if decoder_input.size(1) == max_len:\n",
        "            break\n",
        "\n",
        "        # build mask for target\n",
        "        decoder_mask = causal_mask(decoder_input.size(1)).type_as(source_mask).to(device)\n",
        "\n",
        "        # calculate output\n",
        "        out = model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n",
        "\n",
        "        # get next token\n",
        "        prob = model.project(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        decoder_input = torch.cat(\n",
        "            [decoder_input, torch.empty(1, 1).type_as(source).fill_(next_word.item()).to(device)], dim=1\n",
        "        )\n",
        "\n",
        "        if next_word == eos_idx:\n",
        "            break\n",
        "\n",
        "    return decoder_input.squeeze(0)"
      ],
      "metadata": {
        "id": "aBJr-WXkJ-Hn"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_validation(model, validation_ds, tokenizer_src, tokenizer_tgt, max_len, device, print_msg, global_step, writer, num_examples=2):\n",
        "    model.eval()\n",
        "    count = 0\n",
        "\n",
        "    source_texts = []\n",
        "    expected = []\n",
        "    predicted = []\n",
        "\n",
        "    console_width = 80\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in validation_ds:\n",
        "            count += 1\n",
        "            encoder_input = batch[\"encoder_input\"].to(device) # (B, seq_len)\n",
        "            encoder_mask = batch[\"encoder_mask\"].to(device) # (B, 1, 1, seq_len)\n",
        "\n",
        "            # check that the batch size is 1\n",
        "            assert encoder_input.size(0) == 1, \"Batch size must be 1 for validation\"\n",
        "\n",
        "            model_out = greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, max_len, device)\n",
        "\n",
        "            source_text = batch[\"src_text\"][0]\n",
        "            target_text = batch[\"tgt_text\"][0]\n",
        "            model_out_text = tokenizer_tgt.decode(model_out.detach().cpu().numpy())\n",
        "\n",
        "            source_texts.append(source_text)\n",
        "            expected.append(target_text)\n",
        "            predicted.append(model_out_text)\n",
        "\n",
        "            # Print the source, target and model output\n",
        "            print_msg('-'*console_width)\n",
        "            print_msg(f\"{f'SOURCE: ':>12}{source_text}\")\n",
        "            print_msg(f\"{f'TARGET: ':>12}{target_text}\")\n",
        "            print_msg(f\"{f'PREDICTED: ':>12}{model_out_text}\")\n",
        "\n",
        "            if count == num_examples:\n",
        "                print_msg('-'*console_width)\n",
        "                break\n",
        "\n",
        "    if writer:\n",
        "        # Evaluate the character error rate\n",
        "        # Compute the char error rate\n",
        "        metric = torchmetrics.CharErrorRate()\n",
        "        cer = metric(predicted, expected)\n",
        "        writer.add_scalar('validation cer', cer, global_step)\n",
        "        writer.flush()\n",
        "\n",
        "        # Compute the word error rate\n",
        "        metric = torchmetrics.WordErrorRate()\n",
        "        wer = metric(predicted, expected)\n",
        "        writer.add_scalar('validation wer', wer, global_step)\n",
        "        writer.flush()\n",
        "\n",
        "        # Compute the BLEU metric\n",
        "        metric = torchmetrics.BLEUScore()\n",
        "        bleu = metric(predicted, expected)\n",
        "        writer.add_scalar('validation BLEU', bleu, global_step)\n",
        "        writer.flush()"
      ],
      "metadata": {
        "id": "NlqnmWbhKNts"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8663HsZzzWd1",
        "outputId": "ecc7476c-d9c3-43f2-c9d2-0c61bd598f73"
      },
      "execution_count": 106,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Max length of source sentence: 309\n",
            "Max length of target sentence: 274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Epoch 00: 100%|██████████| 1819/1819 [14:24<00:00,  2.10it/s, loss=5.981]\n",
            "Processing Epoch 01: 100%|██████████| 1819/1819 [14:22<00:00,  2.11it/s, loss=6.164]\n",
            "Processing Epoch 02: 100%|██████████| 1819/1819 [14:21<00:00,  2.11it/s, loss=5.683]\n",
            "Processing Epoch 03: 100%|██████████| 1819/1819 [14:20<00:00,  2.11it/s, loss=5.678]\n",
            "Processing Epoch 04: 100%|██████████| 1819/1819 [14:22<00:00,  2.11it/s, loss=5.992]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
        "model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
        "\n",
        "# Load the pretrained weights\n",
        "model_filename = latest_weights_file_path(config)\n",
        "state = torch.load(model_filename)\n",
        "model.load_state_dict(state['model_state_dict'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYZayfiSLVtz",
        "outputId": "521090f7-09ea-4976-c40c-30c2edacaf65"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length of source sentence: 309\n",
            "Max length of target sentence: 274\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: print(msg), 0, None, num_examples=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oTt4AYZK39D",
        "outputId": "44985241-f45b-4bee-9093-1cb0c2699ff4"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'What hope can you have?' said Betsy, offended on her friend's behalf: 'entendons nous!' But in her eyes little sparks twinkled which said that she understood very well, and just as he did, what hope he might have.\n",
            "    TARGET: — Che speranza potete mai avere? — disse Betsy offesa per l’amica — entendons nous. — Ma nei suoi occhi saltellava un focherello che diceva come ella capisse molto bene, e proprio alla stessa guisa di lui, quale fosse la sua speranza.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il viso , — disse , — disse , e .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: _May_ 6.—Worked on the wreck; got several iron bolts out of her and other pieces of ironwork. Worked very hard, and came home very much tired, and had thoughts of giving it over.\n",
            "    TARGET: 6. Impiegato nello stesso lavoro; e trattine parecchi catenacci ed altri ferramenti; ottenuti con grande stento e portati a casa con tanta fatica, che mi trovai stanco da vero ed in procinto di abbandonare l’opera.\n",
            " PREDICTED: Il suo viso di nuovo , e il suo viso , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'Oh, you know one another?' asked the host.\n",
            "    TARGET: — Ah, vi conoscete? — disse la padrona di casa.\n",
            " PREDICTED: — Sì , signore , — disse il portiere .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: I have lived many years, and now in you for the first time I have met what I was in search of.\n",
            "    TARGET: Ho vissuto una lunga vita e, adesso, per la prima volta ho incontrato in voi quello che cercavo.\n",
            " PREDICTED: E , non si può essere , ma non si poteva essere di lei , ma non poteva essere , e , ma non si .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: To achieve it and to love in comfort and unhampered, the only way is to marry!\n",
            "    TARGET: C’è un solo mezzo per amare comodamente e scansare gli ostacoli, e questo mezzo è il matrimonio.\n",
            " PREDICTED: E , e si mise a lui .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: I ought then to have left my husband and begun life anew.\n",
            "    TARGET: Allora io dovevo abbandonare mio marito e cominciare a vivere di nuovo.\n",
            " PREDICTED: — Sì , — disse il viso , e si mise a un ’ ic , e , e , e , e , e si mise a un ’ ic , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e si mise a un ’ ic , e , e , e , e , e , e si mise a un ’ ic .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: As for me, having some money in my pocket, I travelled to London by land; and there, as well as on the road, had many struggles with myself what course of life I should take, and whether I should go home or to sea.\n",
            "    TARGET: Che strada abbia tenuto in appresso, lo ignoro; quanto a me, avendo un po’ di danaro nella mia borsa, m’avviai per terra a Londra, e sì in questa città e sì lungo il cammino ebbi molte lotte con me medesimo intorno al genere di vita che avrei abbracciato, sempre perplesso fra il tornare a casa ed il rimettermi in mare.\n",
            " PREDICTED: E non poteva dire , e , e , e , e che non poteva , e , e che non poteva dire , e che non poteva dire , e , e , e , e che non poteva dire , e , e che non poteva dire , e che non poteva dire , e , e , e , e , e che non poteva dire , e , e , e che non poteva dire , e che non poteva dire , e , e , e , e , e , e , e che non poteva dire , e , e , e , e , e , e , e , e , e , e , e , e , e che non poteva dire , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e che non poteva dire , e , e , e , e , e , e , e , e , e , e che non poteva dire , e , e , e , e , e che non poteva dire , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Sometimes he would sit for half an hour gazing at the saffron and red downy, wrinkled little face of the sleeping infant, watching the movements of the frowning little forehead and the plump little hands with the bent fingers and palms that rubbed the tiny eyes and nose.\n",
            "    TARGET: A volte guardava in silenzio per una mezz’ora intera il visino addormentato rosso-zafferano, lanuginoso e grinzoso della bambina e osservava i movimenti della fronte aggrottata e le manine paffute con le dita ripiegate che col dorso si fregavano gli occhietti e la radice del naso.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il suo fratello , e , e , e , e , e , e , e , e il suo marito , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e ,\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"Who the deuce have you been with?\"\n",
            "    TARGET: — Con chi diavolo siete stata?\n",
            " PREDICTED: — Sì , signore , signore , — disse .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Lady Lynn had remarked, \"It is Mr. Rochester's ward, I suppose--the little French girl he was speaking of.\"\n",
            "    TARGET: — Credo, — disse lady Lynn, — che sia pupilla del signor Rochester, quella francesina di cui ci ha parlato.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il viso , — disse , — disse , e .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Our family always hated cats: nasty, low, vulgar things! Don't let me hear the name again!'\n",
            "    TARGET: La nostra famiglia ha odiato sempre i gatti; bestie sozze, volgari e basse! non me li nominare più.\n",
            " PREDICTED: — Sì , signore , — disse il portiere .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Come this evening; Alexis Alexandrovich is going to the Council and will remain there till ten.'\n",
            "    TARGET: Venite di sera. Alle sette Aleksej Aleksandrovic va al consiglio e vi rimane fino alle dieci”.\n",
            " PREDICTED: E , non si può essere , e non si .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"I shall be very glad to do so, sir.\"\n",
            "    TARGET: — Lo faccio volentieri, signore.\n",
            " PREDICTED: — Sì , signore , signore , signore , signore .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: A physical miracle would have tempted me. But here is a miracle, the one possible, everlasting miracle, all around me, and I did not notice it!\n",
            "    TARGET: Ed ecco il miracolo, l’unico possibile, continuamente attuale, che da ogni parte mi circonda, e io non me ne accorgevo!\n",
            " PREDICTED: E non si può dire , ma non si poteva rispondere , ma non si poteva dire , ma non si , ma non si , e , e la sua moglie .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: But nevertheless Lydia Ivanovna's help was in the highest degree effective, for it gave Karenin the moral support of the consciousness of her affection and respect, and especially of the fact that she had nearly converted him to Christianity (as it consoled her to believe); that is to say, she had changed him from an apathetic, indolent believer into a fervent and firm adherent of that new interpretation of the Christian teaching which had lately spread in Petersburg.\n",
            "    TARGET: L’aiuto di Lidija Ivanovna fu, tuttavia, molto efficace: ella dette un appoggio morale ad Aleksej Aleksandrovic con la coscienza del suo amore e della sua considerazione per lui, e soprattutto col riportarlo al cristianesimo, pensiero per lei consolante; lo trasformò cioè da indifferente e pigro credente in un appassionato e convinto seguace di quella nuova interpretazione della dottrina cristiana che negli ultimi tempi si era diffusa a Pietroburgo.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il viso , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Meeting his look, her face suddenly assumed a coldly severe expression, as if to say: 'It is not forgotten.\n",
            "    TARGET: Nell’incontrare lo sguardo di lui, il viso di Anna, d’un tratto, prese un’espressione dura, come a dirgli: “Non è dimenticato.\n",
            " PREDICTED: E non si può dire , ma non si sentiva , ma non si sentiva .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: When the elder brother, having a number of debts, married the Princess Varya Chirkova, the daughter of a penniless Decembrist, Alexis gave up to his brother the income from his father's fortune, stipulating for only 25,000 roubles a year for himself.\n",
            "    TARGET: Al tempo in cui il fratello maggiore, pieno di debiti, s’era ammogliato con la principessina Varja cirkova, figlia del decabrista, senza un soldo, Aleksej aveva ceduto al fratello maggiore tutta la rendita del patrimonio paterno, riservando per sé solo 25.000 rubli all’anno.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il suo fratello , e , e , e il suo fratello , e , e , e , e , e , e , e , e , e , e il suo fratello , e il suo fratello , e , e , e , e , e , e il suo fratello , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e il suo fratello , e , e , e , e il suo fratello , e , e , e , e il suo fratello , e il suo fratello , e il suo fratello , e il suo fratello , e , e il suo fratello , e il suo fratello , e , e , e il suo fratello , e il suo fratello , e , e , e , e il suo fratello , e , e , e il suo fratello , e , e il suo fratello , e , e , e , e , e , e , e , e , e , e , e , e , e il suo fratello , e il suo fratello , e il suo fratello , e il suo fratello , e , e il suo fratello , e il suo fratello , e il suo fratello , e il suo fratello , e il suo fratello , e il suo fratello , e , e , e il suo fratello , e , e , e il suo fratello , e il suo fratello , e , e , e , e , e , e il suo fratello , e , e , e , e , e , e , e , e il suo fratello , e il suo fratello , e , e ,\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Levin listened, trying but unable to think of what to say.\n",
            "    TARGET: Levin ascoltava e cercava e non sapeva trovare cosa dire.\n",
            " PREDICTED: E non si può dire .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Again the Volunteers bowed and thrust their heads out, but Koznyshev did not pay attention to them: he had had so much to do with Volunteers that he was already familiar with their general type and it did not interest him.\n",
            "    TARGET: Di nuovo i volontari salutarono e sporsero le teste, ma Sergej Ivanovic non prestò loro attenzione: aveva avuto già tanto a che fare con i volontari che ne conosceva ormai le caratteristiche, e tutto questo non lo interessava più.\n",
            " PREDICTED: E , e si sentiva , e la sua sua sua sua sua sua sua sua moglie , e il suo viso .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Between the Princess Betsy Tverskaya and Oblonsky there existed long-established and very peculiar relations.\n",
            "    TARGET: Fra la principessa Betsy Tverskaja e Stepan Arkad’ic esistevano vecchi rapporti, molto strani.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il viso , e si mise a un ’ ic , e , e il suo viso .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Will you show me the way? And please find out whether Count Anichkin' (the new superior) 'will receive me.'\n",
            "    TARGET: — Sissignore — rispose Vasilij, sorridendo. — È un pezzo che attendiamo i vostri ordini.\n",
            " PREDICTED: — Sì , signore , — disse il portiere , — disse , — disse , — disse , — disse il suo fratello .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: He recalled the timid pathetic look with which Anna at parting from him had said: 'Anyhow, you will see him.\n",
            "    TARGET: E ricordò l’espressione timida, pietosa con cui, lasciandolo andar via, aveva detto: “Tuttavia lo vedrai.\n",
            " PREDICTED: E non si può dire , ma non si può essere nulla .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: He was taken out from under the ruins, alive, but sadly hurt: a beam had fallen in such a way as to protect him partly; but one eye was knocked out, and one hand so crushed that Mr. Carter, the surgeon, had to amputate it directly.\n",
            "    TARGET: Fu tolto vivo di sotto le rovine, ma ferito gravemente. Una trave era caduta in modo da proteggerlo in parte, ma un occhio gli era schizzato fuori dalla testa e una mano era così fracassata che il signor Carter, il chirurgo, dovette amputargliela subito.\n",
            " PREDICTED: E , e si , e la sua mano .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'I... I want to tell you that it's impossible to live like this – it's torture!' she muttered.\n",
            "    TARGET: — Io... io voglio dire che così non si può vivere, che è un tormento... — ella pronunciò.\n",
            " PREDICTED: — Sì , — disse il viso , — disse , — disse , — disse , — disse il viso , — disse il viso , — disse il viso , — disse , — disse , — disse , — disse , — disse il viso , — disse il viso , — disse il viso , — disse il viso , — disse il viso , — disse il viso , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse , — disse il viso , — disse , — disse , — disse il viso , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse il viso , — disse , — disse il viso , — disse , — disse , — disse , — disse il viso , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse il viso , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse , — disse il viso , — disse , — disse il viso , — disse , — disse il viso , — disse , — disse , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse il viso , — disse il viso , — disse il viso\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'But about his toes?' the Mock Turtle persisted. 'How could he turn them out with his nose, you know?'\n",
            "    TARGET: — A proposito di piedi, — continuò la Falsa-testuggine, — come poteva rivoltarli, e col naso, per giunta?\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il viso .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: The first was a tall lady with dark hair, dark eyes, and a pale and large forehead; her figure was partly enveloped in a shawl, her countenance was grave, her bearing erect.\n",
            "    TARGET: La prima era una donna alta, con occhi e capelli neri, con la fronte spaziosa e pallida. Benché fosse avvolta in uno scialle, mi parve che la sua figura fosse nobile e grave il contegno.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il suo fratello , e il suo marito , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e ,\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: No, I am not even proud.\n",
            "    TARGET: Ma non è orgoglio.\n",
            " PREDICTED: — Sì , signore , — disse il viso , — disse , — disse , — disse , — disse il viso .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: As we re-entered the carriage, and I sat back feverish and fagged, I remembered what, in the hurry of events, dark and bright, I had wholly forgotten--the letter of my uncle, John Eyre, to Mrs. Reed: his intention to adopt me and make me his legatee.\n",
            "    TARGET: Quando mi sedei in carrozza, scossa e febbricitante, mi rammentai di quello che in tanta agitazione aveva del tutto dimenticato: della lettera di mio zio alla signora Reed, della intenzione che egli aveva di adottarmi e di lasciarmi il suo.\n",
            " PREDICTED: E non si poteva essere più , ma non poteva rispondere , ma non si , ma non si , ma non si , ma non poteva dire , e la sua sua moglie .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: In spirit, I believe we must have met.\n",
            "    TARGET: \"Dovevamo esserci incontrati in ispirito, credo.\n",
            " PREDICTED: E non si può dire .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'Give him your hand. Forgive him.'\n",
            "    TARGET: — Dàgli la mano, perdonagli.\n",
            " PREDICTED: — Sì , signore , signore , — disse .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: I told her stories as long as she would listen to them; and then for a change I took her out into the gallery.\n",
            "    TARGET: Le raccontai tante novelle, poi per distrarla la condussi nel corridoio.\n",
            " PREDICTED: E , non si può essere , e non si poteva essere di , e di .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: He carefully avoided the musical experts and great talkers, and stood with lowered eyes gazing straight before him, listening.\n",
            "    TARGET: Cercava di evitare incontri con intenditori di musica e ciarlatori, guardando in giù davanti a sé, e ascoltando.\n",
            " PREDICTED: E , e si , e la sua mano .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: I only feel comfortable with children, only in your house.'\n",
            "    TARGET: Soltanto coi bambini sto bene. Soltanto da te.\n",
            " PREDICTED: — Sì , signore , — disse .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: A flush of animation suffused Karenin's face as he rapidly wrote out a summary of these ideas.\n",
            "    TARGET: 36. Un colorito di animazione copriva a poco a poco il viso di Aleksej Aleksandrovic mentre egli fissava in breve lo schema di queste idee.\n",
            " PREDICTED: — Sì , signore , — disse il portiere .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'Where are you?' seemed spoken amongst mountains; for I heard a hill-sent echo repeat the words.\n",
            "    TARGET: \"— Dove siete? — pareva che fosse stato pronunziato su una montagna, perché quelle parole furono ripetute dall'eco.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il viso .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: The barbarity of this spectacle caused the people to be at once satisfied and dismayed.\n",
            "    TARGET: La ferocità del quale spettaculo fece quelli populi in uno tempo rimanere satisfatti e stupidi.\n",
            " PREDICTED: E , e si mise a lui .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Mr. Rochester looks as young, and is as young, as some men at five-and- twenty.\"\n",
            "    TARGET: Il signor Rochester par giovane ed è certo giovane come un uomo di venticinque anni.\n",
            " PREDICTED: E non si può dire , ma non si poteva rispondere , ma non si , e non si .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"I thought you would be revolted, Jane, when you saw my arm, and my cicatrised visage.\"\n",
            "    TARGET: — Credevo, Jane, che avreste provato ribrezzo vedendomi in questo stato.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il viso .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'Well, let's grant it is so,' said Levin, though he did not grant it at all. 'Still, I don't see why I should he bothered with it.'\n",
            "    TARGET: — Su, ammettiamo — disse Levin, sebbene non lo ammettesse per nulla — ammettiamo pure che sia così; ma io tuttavia non vedo la necessità di dovermi affannare per questo.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il signor Rochester , — disse il signor Rochester , — disse , — disse il signor Rochester , — disse , — disse , — disse , — disse , — disse , — disse il signor Rochester , — disse il signor Rochester , — disse , — disse , — disse , — disse il signor Rochester , — disse il signor Rochester , — disse il signor Rochester , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse il signor Rochester , — disse , — disse , — disse , — disse , — disse , — disse il signor Rochester , — disse , — disse , — disse , — disse , — disse , — disse , — disse il signor Rochester , — disse , — disse , — disse il signor Rochester , — disse , — disse il signor Rochester , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse il signor Rochester , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse il signor Rochester , — disse il signor Rochester , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse il signor Rochester , — disse , — disse , — disse il signor Rochester , — disse il signor\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: The Secretary knocked, the door opened and two landowners with flushed faces plunged out past Levin.\n",
            "    TARGET: Il segretario picchiò: la porta si aprì e incontro a Levin scivolarono via due proprietari, rossi in viso.\n",
            " PREDICTED: E , e si mise a lui .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: When Levin had read the note, holding it in his hand, he remained standing in front of Koznyshev without lifting his head.\n",
            "    TARGET: Levin lesse e, senza alzar la testa, rimase in piedi davanti a Sergej Ivanovic col biglietto in mano.\n",
            " PREDICTED: E , non si può essere , ma non si può essere .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Oblonsky evidently wanted the same thing, and on his face Levin noticed the preoccupation, which every true sportsman feels before the shooting begins, and also a little good-natured cunning, characteristic of him.\n",
            "    TARGET: Stepan Arkad’ic, evidentemente desiderava anche lui questo, e sul suo viso Levin scorse l’espressione ansiosa che ha il cacciatore prima di cominciare la caccia, mista a una certa bonaria furberia che gli era propria.\n",
            " PREDICTED: E , non si può essere , ma non si può essere di lei , ma Aleksandrovic , ma Aleksandrovic , ma Aleksandrovic , ma non poteva essere , ma non poteva essere , ma Aleksandrovic , ma Aleksandrovic , ma Aleksandrovic , ma non poteva essere nulla .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Everything was so out of the ordinary that nothing any longer surprised Levin.\n",
            "    TARGET: Tutto era così fuori dell’ordinario, che Levin non si stupiva più di nulla.\n",
            " PREDICTED: E non si può dire .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'What can I do?' said Karenin, shrugging his shoulders and raising his eyebrows.\n",
            "    TARGET: — Che posso farci? — disse Aleksej Aleksandrovic, dopo aver alzato le spalle e le sopracciglia.\n",
            " PREDICTED: — Sì , signore , — disse il portiere .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: He raised his head.\n",
            "    TARGET: Egli sollevò il capo.\n",
            " PREDICTED: E non si può dire .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"A mean nutriment for the spirit to exist on: and sitting in that window- seat (you see I know your habits )--\" \"You have learned them from the servants.\"\n",
            "    TARGET: — Queste idee bastano a divagare soltanto l'immaginazione quando state seduta accanto alla finestra; vedete che conosco le vostre consuetudini.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il viso , — disse , — disse , e , — disse , — disse il suo marito .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: The other side of what?' thought Alice to herself.\n",
            "    TARGET: L'altro lato di che cosa?” pensò Alice fra sè.\n",
            " PREDICTED: E non si può dire .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: And now Simon...'\n",
            "    TARGET: Ma ecco Semën....\n",
            " PREDICTED: — Sì , signore , signore , — disse .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Galtsin, one of the formidable competitors and a friend of Vronsky's, was struggling with a sorrel gelding that would not let him mount.\n",
            "    TARGET: Gal’cin, uno degli antagonisti temibili, amico di Vronskij, si aggirava intorno a uno stallone che non si lasciava montare.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il viso , — disse , — disse , e si mise a un sorriso .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: I only entertained the intention for a moment; for, not being insane, the crisis of exquisite and unalloyed despair, which had originated the wish and design of self-destruction, was past in a second.\n",
            "    TARGET: \"Volevo uccidermi, ma quel desiderio fu di breve durata, perché non ero pazzo, e quella crisi di dolore infinito, che aveva generato il desiderio e il disegno del suicidio, era svanita in un secondo.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il suo fratello , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: But he saw that this was necessary to her, and, loving her, though he could not understand what it was all about, and laughed at her worries, he could not help admiring them.\n",
            "    TARGET: Ma vedeva che questo le era indispensabile. E amandola, pur irridendo a queste preoccupazioni, senza saperne il perché, non poteva non compiacersene.\n",
            " PREDICTED: E , non si può essere , ma non si può essere di lei , ma Aleksandrovic , ma Aleksandrovic , ma Aleksandrovic , ma non poteva essere , ma Aleksandrovic , ma Aleksandrovic , ma Aleksandrovic , ma non poteva essere nulla .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"Well, Blanche?\" said Lord Ingram.\n",
            "    TARGET: — Ebbene, Bianca? — domandò lord Ingram.\n",
            " PREDICTED: — Sì , signore , signore , signore , signore , signore , signore .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: It was the White Rabbit returning, splendidly dressed, with a pair of white kid gloves in one hand and a large fan in the other: he came trotting along in a great hurry, muttering to himself as he came, 'Oh! the Duchess, the Duchess!\n",
            "    TARGET: Era il Coniglio bianco di ritorno, splendidamente vestito, con un paio di guanti bianchi in una mano, e un gran ventaglio nell'altra: trotterellava frettolosamente e mormorava: “Oh! la Duchessa, la Duchessa!\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il viso , — disse , — disse , e .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Being aware of this and of the fact that any expression he could at that moment find for his feelings would be incompatible with the situation, he tried to conceal all signs of life within himself and neither moved nor looked at her.\n",
            "    TARGET: Sapendo ciò e sapendo che in quel momento la manifestazione dei suoi sentimenti non sarebbe stata adatta alla situazione, si era sforzato di contenere dentro di sé ogni moto di vita, e perciò era rimasto immobile senza guardarla.\n",
            " PREDICTED: E , non si può essere , e non si poteva essere di , e di , e di , e di , e di , e , e , e di , e , e , e di , e di , e di , e di , e di , e , e di , e , e di , e , e , e di , e di , e di , e di , e , e , e di , e di , e di , e di , e , e di , e , e di , e di , e di , e , e di , e di , e di , e , e , e di , e di , e di , e di , e di , e di , e di , e , e di , e di , e di , e di , e di , e di , e , e di , e di , e di , e di , e di , e di , e , e di , e , e di , e di , e di , e di , e di , e di , e di , e di , e di , e di , e di , e , e di , e , e , e di , e di , e di , e , e , e di , e di , e di , e di , e , e , e di , e di , e di , e , e di\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'And who was inside the cart?\n",
            "    TARGET: E chi c’era mai nella carretta?\n",
            " PREDICTED: — Sì , signore , — disse il portiere .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: I will tell anybody who asks me questions, this exact tale.\n",
            "    TARGET: Dirò la pura verità a tutti quelli che m'interrogheranno.\n",
            " PREDICTED: — Sì , signore , — disse il viso .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: I tell you this plainly; and listen: for though I shall no more repeat what I am now about to say, I shall steadily act on it.\n",
            "    TARGET: \"Vi parlerò francamente; quello che sto per dirvi non lo ripeterò più, ma agirò in conseguenza.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il viso , — disse , — disse , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: She paused, unable to invent a reason.\n",
            "    TARGET: Si fermò non trovando nessuna giustificazione.\n",
            " PREDICTED: E non si può dire .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: At that moment Captain Yashvin, a tall man with a fine figure, entered the room, and having given a contemptuous backward nod to the two officers he came up to Vronsky.\n",
            "    TARGET: In quel momento entrò nella sala il capitano Jašvin, alto e ben fatto, che, con un cenno sprezzante all’insù del capo verso i due ufficiali, s’accostò a Vronskij.\n",
            " PREDICTED: E non si può essere più di lui , e non poteva dire , ma non si .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: What's good for the master is good for us too.\n",
            "    TARGET: Se va bene per il padrone, va bene anche per noi.\n",
            " PREDICTED: — Sì , — disse il viso , — disse .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: I could not see anything to laugh at, and I told George so, and he only laughed the more.\n",
            "    TARGET: Io non ci vedevo nulla da ridere, e glielo dissi; ma egli si mise a ridere più forte.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il suo fratello , e si mise a un sorriso .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: From this they immediately jumped to the conclusion that it was I, their beloved companion, who was making an exhibition of himself, and their delight knew no bounds.\n",
            "    TARGET: Da questo immediatamente saltarono alla conclusione che fossi io, il loro diletto amico, che facesse mostra della propria abilità, e la loro gioia non ebbe limiti.\n",
            " PREDICTED: E , non si può essere , e che non si .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Something magical has happened to me: like a dream when one feels frightened and creepy, and suddenly wakes up to the knowledge that no such terrors exist.\n",
            "    TARGET: M’è accaduto qualcosa di magico, come quando in un sogno si prova spavento, impressione e a un tratto ci si sveglia e si sente che tutti quegli spaventi non esistono.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il viso , e si mise a un ’ ic , e , e il suo viso .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: The only difference was that he was even more occupied than before.\n",
            "    TARGET: L’unica differenza consisteva nel fatto che egli era più occupato di prima.\n",
            " PREDICTED: E non si può dire .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: He was told that, soon after he left, a lady came to see her and they went away together.\n",
            "    TARGET: Gli dissero che, subito dopo di lui, era venuta una signora ed ella era uscita con lei.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il viso , e si mise a un ’ ic , e , e si mise a un ’ ic , e , e , e , e si mise a un ’ ic , e , e si mise a un ’ ic , e , e , e si mise a un ’ ic , e , e , e si mise a un ’ ic , e , e si mise a un ’ ic , e si mise a un ’ ic , e , e si mise a un ’ ic , e , e , e si mise a un ’ ic , e , e , e si mise a un ’ ic , e , e , e , e , e , e si mise a un ’ ic , e , e si mise a un ’ ic , e , e , e , e si mise a un ’ ic , e , e , e , e si mise a un ’ ic , e , e , e , e , e , e , e si mise a un ’ ic , e , e , e si mise a un ’ ic , e , e , e , e , e , e , e , e , e si mise a un ’ ic , e , e , e , e , e , e , e , e , e , e , e si mise a un ’ ic Aleksandrovic\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Do you know what he has done?'\n",
            "    TARGET: Lo sai cosa ha fatto...\n",
            " PREDICTED: — Sì , signore , — disse il portiere .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'And her health?'\n",
            "    TARGET: — E come va la salute?\n",
            " PREDICTED: — Sì , signore , — disse .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: When I awoke, I found myself much refreshed, but weak, and exceeding thirsty. However, as I had no water in my habitation, I was forced to lie till morning, and went to sleep again.\n",
            "    TARGET: Nello svegliarmi mi sentii alquanto ristorato, benchè debole e assetato oltre ogni dire; ma non avendo acqua in tutta quanta la mia abitazione, fui costretto aver pazienza sino a giorno; tornai pertanto ad addormentarmi.\n",
            " PREDICTED: E non si può dire , e non poteva , e , e , e , e non poteva capire che non poteva capire che non poteva capire che non poteva dire , e , e , e , e , e , e non poteva dire , e , e , e , e il suo fratello , e , e , e , e , e , e , e , e di .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Coming now to the other qualities mentioned above, I say that every prince ought to desire to be considered clement and not cruel. Nevertheless he ought to take care not to misuse this clemency.\n",
            "    TARGET: Scendendo appresso alle altre preallegate qualità, dico che ciascuno principe debbe desiderare di essere tenuto pietoso e non crudele: non di manco debbe avvertire di non usare male questa pietà.\n",
            " PREDICTED: E non si può essere più di , e non poteva , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e ,\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: A ceremony followed, in dumb show, in which it was easy to recognise the pantomime of a marriage. At its termination, Colonel Dent and his party consulted in whispers for two minutes, then the Colonel called out--\n",
            "    TARGET: Allora incominciò una cerimonia, nella quale era facile riconoscere la pantomima di un matrimonio, e, terminata che fu, il colonnello Dent, dopo aver consultato i suoi vicini, disse:\n",
            " PREDICTED: E , non si può essere , ma non si poteva essere di , e di , e di , e di , e di , e , e , e di , e , e , e di , e di , e di , e di , e di , e , e di , e , e di , e , e , e di , e di , e di , e di , e , e , e di , e di , e di , e di , e , e di , e , e di , e di , e di , e , e di , e di , e di , e di , e di , e , e di , e di , e di , e di , e di , e , e di , e , e , e di , e di , e , e di , e di , e di , e di , e di , e , e , e di , e , e di , e , e di , e di , e di , e di , e , e di , e di , e , e di , e , e di , e di , e , e di , e di , e di , e di , e di , e di , e , e , e di , e , e di , e di , e di , e di , e di , e , e , e , e di , e di , e di\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"Yes, sir.\"\n",
            "    TARGET: — Molto strana, signore.\n",
            " PREDICTED: — Sì , signore , signore .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: So, eventually, he made one final arrangement with himself, which he has religiously held to ever since, and that was to count each fish that he caught as ten, and to assume ten to begin with.\n",
            "    TARGET: Così fu costretto a ricorrere a un’altra decisione, alla quale si tenne poi religiosamente sempre, e cioè di contare ciascun capo per dieci, e di fingerne dieci iniziali.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il viso , e si mise a un ’ ic , e , e il suo viso .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: He wished to say that he had been up all night and had fallen asleep, but seeing her excited and happy face he felt ashamed.\n",
            "    TARGET: Egli voleva dire che non aveva dormito la notte e che perciò aveva preso sonno, ma guardando il viso agitato e felice di lei, ebbe rimorso.\n",
            " PREDICTED: E che non si può essere più di lei , e , ma non si .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: If, in the moments I and my pupil spent with him, I lacked spirits and sank into inevitable dejection, he became even gay.\n",
            "    TARGET: Nei momenti che io e la mia alunna stavamo con lui, se vedeva mancarmi il coraggio, cercava d'essere allegro.... Una splendida estate brillava sull'Inghilterra; il cielo puro e il sole raggiante raramente splendono sul nostro paese per un sol giorno, mentre ora ci rallegravano da molto tempo.\n",
            " PREDICTED: E , e si mise a un ’ ic , e , e , e , e , e , e , e , e si mise a un ’ ic , e la sua mano .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: I respect or despise both so much – I respect your past and despise your present that the interpretation you give to my words was far from my thoughts!'\n",
            "    TARGET: Per quel tanto che io rispetto e disprezzo e questo e quello.... rispetto il vostro passato, ma disprezzo il presente... ero ben lontano dalla interpretazione che voi avete dato alle mie parole.\n",
            " PREDICTED: E non si può essere più di lei , e il suo amore .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: I am not strange, but wicked.\n",
            "    TARGET: Non sono strana, sono cattiva.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il viso .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: In guarantee whereof, I attached myself to my seat by my hands.\n",
            "    TARGET: E per dare una prova di ciò che asserivo, mi avviticchiai alla sedia.\n",
            " PREDICTED: E che non si può essere più di , e il suo marito .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Mr. Mason shortly unclosed his eyes; he groaned. Mr. Rochester opened the shirt of the wounded man, whose arm and shoulder were bandaged: he sponged away blood, trickling fast down.\n",
            "    TARGET: Il signor Rochester aprì la camicia del ferito, il quale aveva il braccio e il fianco fasciato e rasciugò il sangue.\n",
            " PREDICTED: E , e , e , e la sua mano , e la sua mano , e la sua mano , e la sua mano , e la sua mano , e la sua mano , e la sua mano , e la sua mano , e il suo viso , e la sua vita , e la sua vita , e il suo viso , e il suo viso , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e il suo viso , e la sua vita , e la sua vita , e la sua vita , e il suo viso , e il suo viso , e la sua vita , e la sua vita , e il suo viso , e il suo viso , e il suo viso , e il suo viso , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e il suo viso , e la sua vita , e il suo viso , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e il suo viso , e il suo viso , e il suo viso , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e la sua vita , e il suo viso , e la sua vita , e il suo viso , e la sua vita , e il suo viso , e la sua vita , e il suo viso , e la sua vita , e la sua vita , e la sua vita , e il suo viso , e la sua vita , e la sua vita , e il suo viso , e il suo viso , e la sua\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"I did them in the last two vacations I spent at Lowood, when I had no other occupation.\"\n",
            "    TARGET: — Li ho fatti nelle due vacanze a Lowood.\n",
            " PREDICTED: — Sì , signore , — disse il portiere .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: I can recognize a man who has serious intentions – such as Levin – and I can see through a weathercock like that popinjay who only wishes to amuse himself.'\n",
            "    TARGET: Io vedo, da una parte, un uomo che ha intenzioni serie, Levin; e dall’altro un gallinaccio fanfarone come questo qua, che vuole soltanto divertirsi.\n",
            " PREDICTED: E che non si può essere più , e , ma non si .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: No one ever convinces another.'\n",
            "    TARGET: Tanto nessuno mai convincerà l’altro.\n",
            " PREDICTED: — Sì , signore , signore , — disse .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: After a brief stay there, I shall bear my treasure to regions nearer the sun: to French vineyards and Italian plains; and she shall see whatever is famous in old story and in modern record: she shall taste, too, of the life of cities; and she shall learn to value herself by just comparison with others.\"\n",
            "    TARGET: \"Di là condurrò il mio tesoro nelle regioni del sole, fra i vigneti della Francia e nelle pianure italiane, ed ella deve vedere tutto quanto vi è di famoso nella storia antica e nella moderna, deve conoscere la vita delle città e capire che cosa vale, paragonandosi con le altre donne.\n",
            " PREDICTED: E che non si può essere più , e , e , e , e , e , e , e , e , e , e non si , e , e , e la sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: She pulled out of her box, about ten minutes ago, a little pink silk frock; rapture lit her face as she unfolded it; coquetry runs in her blood, blends with her brains, and seasons the marrow of her bones.\n",
            "    TARGET: Dieci minuti fa ha cavato dalla scatola un vestitino di raso rosa; i tratti di lei hanno subito rivelato la gioia. Ha la civetteria nel sangue, nel cervello, e anche nelle ossa.\n",
            " PREDICTED: E che non si può essere più , e , e , e , e , e , e , e , e , e , e non si , e , e , e non si , e , e , e , e la sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua sua\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'It won't hurt, master. \"Mow in the rain, rake when it's fine! \"-'\n",
            "    TARGET: — Non fa nulla, padrone: con la pioggia falcia, col bel tempo rastrella! — disse il vecchio.\n",
            " PREDICTED: — Sì , signore , — disse il portiere .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: BY THE TIME HE REACHED PETERSBURG Karenin had not only resolved to keep to his decision, but had mentally composed a letter to his wife.\n",
            "    TARGET: Avvicinandosi a Pietroburgo, Aleksej Aleksandrovic non solo era risolutamente fermo in questa sua decisione, ma aveva già composta nella sua mente la lettera che avrebbe scritto alla moglie.\n",
            " PREDICTED: — Sì , — disse il viso , — disse , — disse , — disse , — disse il viso .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'Where are the racks from the calves' yard?'\n",
            "    TARGET: — Dove sono le greppie del recinto dei vitelli?\n",
            " PREDICTED: — Sì , signore , — disse .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: CHAPTER XX\n",
            "    TARGET: XX\n",
            " PREDICTED: — Sì , signore , signore .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'What?\n",
            "    TARGET: — Come?\n",
            " PREDICTED: — Sì , signore , signore .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'But what is \"anything\"?'\n",
            "    TARGET: — Ma cosa tutto?\n",
            " PREDICTED: — Sì , signore , — disse il portiere .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"What can possess him to come home in that style?\" said Miss Ingram. \"He rode Mesrour (the black horse), did he not, when he went out? and Pilot was with him:--what has he done with the animals?\"\n",
            "    TARGET: — Perché torna in carrozza? — disse Bianca — è partito a cavallo e Pilato lo accompagnava; che cosa ne ha fatto del cane?\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il viso .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: The wise prince, therefore, has always avoided these arms and turned to his own; and has been willing rather to lose with them than to conquer with the others, not deeming that a real victory which is gained with the arms of others.\n",
            "    TARGET: Uno principe, per tanto, savio, sempre ha fuggito queste arme, e voltosi alle proprie; et ha volsuto più tosto perdere con li sua che vincere con li altri, iudicando non vera vittoria quella che con le armi aliene si acquistassi.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il suo fratello , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: My second daughter, Augusta, went with her mama to visit the school, and on her return she exclaimed: 'Oh, dear papa, how quiet and plain all the girls at Lowood look, with their hair combed behind their ears, and their long pinafores, and those little holland pockets outside their frocks--they are almost like poor people's children! and,' said she, 'they looked at my dress and mama's, as if they had never seen a silk gown before.'\"\n",
            "    TARGET: — La mia figlia secondogenita, — continuò dopo una pausa il signor Bockelhurst, — è andata insieme con sua madre a visitare l'Istituto, e tornando ha esclamato: \"Oh babbo! Quelle bimbe di Lowood, come paiono tranquille e semplici, con i capelli rialzati d'oltre l'orecchio, con i loro lunghi grembiuli, con i loro vestiti, con le tasche cucite di fuori!\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il suo fratello , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: Not once since our marriage have I said to myself that things might have been better than they are...'\n",
            "    TARGET: Non è avvenuto neppure una volta, da che sono sposato, che io abbia detto che sarebbe stato meglio altrimenti di quello che non sia...\n",
            " PREDICTED: — Sì , signore , — disse il portiere .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: It was not his brother.\n",
            "    TARGET: Non era il fratello.\n",
            " PREDICTED: — Sì , signore , — disse , — disse .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: See, feel my shirt, it's not damp!'\n",
            "    TARGET: Guarda, tocca la camicia. Niente sudore?\n",
            " PREDICTED: — Sì , — disse il viso , — disse , — disse , — disse , — disse il viso , — disse il viso , — disse il viso , — disse , — disse , — disse , — disse , — disse il viso , — disse il viso , — disse il viso , — disse il viso , — disse il viso , — disse il viso , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse , — disse il viso , — disse , — disse , — disse il viso , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse il viso , — disse , — disse il viso , — disse , — disse , — disse , — disse il viso , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse il viso , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse , — disse il viso , — disse , — disse il viso , — disse , — disse il viso , — disse , — disse , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse il viso , — disse il viso , — disse il viso\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"Oh no, sir, I think it will clear up all right. It will break all right enough, sir.\"\n",
            "    TARGET: — Ah, no, signore, io credo che si rischiarerà, e sarà abbastanza bello.\n",
            " PREDICTED: — Sì , signore , signore , signore , signore , signore , signore , signore , signore , signore , — disse .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: I have forbidden Adele to talk to me about her presents, and she is bursting with repletion: have the goodness to serve her as auditress and interlocutrice; it will be one of the most benevolent acts you ever performed.\"\n",
            "    TARGET: Ho proibito a Adele di parlarmi del dono che le ho fatto, vedo che ne ha una gran voglia; abbiate la cortesia di servirle di interlocutrice, non avrete mai fatto un atto di carità più vera.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il suo fratello , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e , e\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: What?...\n",
            "    TARGET: Cos’è?\n",
            " PREDICTED: CAPITOLO XVI\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: 'What did they draw?' said Alice, quite forgetting her promise.\n",
            "    TARGET: — Che cosa traevano? — domandò Alice, dimenticando che aveva promesso di tacere.\n",
            " PREDICTED: — Sì , signore , — disse il portiere .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: \"I think not; and if I were, it does not much signify; I shall never be called upon to contend for such another.\n",
            "    TARGET: — Non credo, ma del resto che cosa importa? Non dovrò più combattere per quella stessa causa; la vittoria è definitiva.\n",
            " PREDICTED: — Sì , — disse , — disse , — disse , — disse il viso , — disse , — disse , e , — disse , — disse il viso , — disse , — disse il viso , — disse , — disse , — disse il viso , — disse , — disse , — disse il viso , — disse , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse il viso , — disse , e , — disse , — disse , — disse il viso , — disse , — disse , — disse , — disse , — disse , — disse , e , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse , — disse il viso , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse , — disse , — disse , — disse , — disse , — disse il viso , — disse , — disse il viso , — disse , — disse il viso , — disse , — disse\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PREDICTIONS ARE NOT GODD TRY IMPROVING THE HYPERPARAMETERS IN THE CONFIG AND RUN FOR MORE TIME"
      ],
      "metadata": {
        "id": "Y0j992pqMKAL"
      },
      "execution_count": 115,
      "outputs": []
    }
  ]
}